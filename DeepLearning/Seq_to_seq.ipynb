{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq_to_seq.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNE5NM4h6mvgJAq317Vm2Gw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"G8sEZqpPozyj"},"source":["*SLOGAN:* **Unless you can teach it, you don't know it**.\n","\n","\n","---\n","\n","\n","This notebook is an adaptation of tensorflow's tutorial to train a sequence to sequence model. It has been adapted to translate sentences from german to english. So yes!!! we will be building our own google translator, although it can translate only one language to the next. It is still a step in the right direction.\n","\n","---\n","**New addition?**\n","1. Encoder-Decoder model.\n","2. Attention mechanism.\n","3. Natural language processing."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LJchL7Door4n","executionInfo":{"status":"ok","timestamp":1627454859265,"user_tz":-120,"elapsed":4887,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}},"outputId":"4a5e6385-3f0f-4438-f100-e394bf35782d"},"source":["pip install tensorflow_addons"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n","\u001b[?25l\r\u001b[K     |▌                               | 10 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 679 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.13.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fGUamhcascgW"},"source":["**Import required Libraries**"]},{"cell_type":"code","metadata":{"id":"b9h6okBkstbD","executionInfo":{"status":"ok","timestamp":1627454862424,"user_tz":-120,"elapsed":3175,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}}},"source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","import os, re, time, io\n","import numpy as np\n","import unicodedata\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import pandas as pd\n","from sklearn.model_selection import train_test_split"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y1Tj4d2CuA2V"},"source":["In this block of our notebook we create **a custom function** and **a custom class**:\n","\n","1. The *make_path* function downloads our data from the Github repo for this course and creates a path to the data for us. \n","\n","---\n","Tensorflow comes with a nice function called get_file, which can download files for us (even in zip format). This function will download the file and store it in the dataset repository. *E.g ~/.keras/datasets/example.txt*\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"5DozsZhguBl-","executionInfo":{"status":"ok","timestamp":1627454862442,"user_tz":-120,"elapsed":37,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}}},"source":["def make_path(url):\n","  path_to_file = tf.keras.utils.get_file('deu.txt', origin=url)\n","  return path_to_file\n","\n","github_url = 'https://raw.githubusercontent.com/PelFritz/Machine-Learning-courses-IPK/master/Data/deu.txt'\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lRqAwTlB3HdP"},"source":["2. The *CreateDataset* class processes every sentence in the file, separating every english sentence with its corresponding german translation. It has a call function which makes the class callable like a function and when we call this class, it will return **train** and **validation** datasets. It will also return **two language tokenizers** to us (one per langauge). \n","\n","\n","---\n","\n","\n","A tokenizer simply takes a sentence and translates it into a nice numeric representaion, so we can feed our models numeric functions."]},{"cell_type":"code","metadata":{"id":"GfnPWXpj3CVq","executionInfo":{"status":"ok","timestamp":1627454862443,"user_tz":-120,"elapsed":32,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}}},"source":["class CreateDataset:\n","  def __init__(self, problem_type='deu-eng'):\n","    self.problem_type= problem_type\n","    self.input_lang_tokenizer= None\n","    self.target_lang_tokenizer= None\n","  \n","  # this function returns the unicode normalized form of words in our text with the exception of nonspacing marks(Mn)\n","  def unicode_verify(self, s):\n","    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n","  \n","\n","  # this function processes each sentence sentence in 3 steps\n","  def preprocess(self, w):\n","    w = self.unicode_verify(w.lower().strip())\n","\n","    # space puntuations and words e.g \"Is Arabidopsis a plant?\" becomes \"Is Arabidopsis a plant ?\"\n","    # collapse all double spacing to single spacing\n","    w = re.sub(r\"([?.!,])\", r\"\\1 \", w)\n","    w = re.sub(\"\\s{2,}\", \" \", w)\n","\n","    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"öüäß\")\n","    w = re.sub(r\"[^a-zA-Z?.!,öüäß]+\", \" \", w)\n","    w = w.strip()\n","\n","    # add <start> and <end> token\n","    w = '<start> ' + w + ' <end>'\n","\n","    return w \n","  \n","  def generate_processed_data(self, url, num_examples):\n","    lines = open(make_path(url), encoding='UTF-8').read().strip().split('\\n')\n","    tot_examples = len(lines)\n","\n","    # if you wish to use all the examples just use tot_examples inplace of num_examples in the code line below\n","    word_pairs = [[self.preprocess(w) for w in line.split('\\t')][:-1] for line in lines[:num_examples]]\n","    \n","    return zip(*word_pairs)\n","  \n","  # This function creates the tokenizers\n","  def tokenize(self, lang):\n","    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<oov>')\n","    lang_tokenizer.fit_on_texts(lang)\n","    tensor = lang_tokenizer.texts_to_sequences(lang)\n","\n","    # we pad all sequences to the length of the longest sentence for the sake of the encoder \n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n","\n","    return tensor, lang_tokenizer\n","  \n","  def load_dataset(self, url, num_examples):\n","    targ_lang, inp_lang = self.generate_processed_data(url, num_examples)\n","\n","    inp_tensor, inp_tok = self.tokenize(inp_lang)\n","    targ_tensor, targ_tok = self.tokenize(targ_lang)\n","\n","    return inp_tensor, targ_tensor, inp_tok, targ_tok\n","  \n","  def __call__(self, BUFFER_SIZE, url, num_examples, batch_size):\n","    inp_tensor, targ_tensor, self.input_lang_tokenizer, self.target_lang_tokenizer = self.load_dataset(url, num_examples)\n","\n","    # split data into train and test sets using sklearn\n","    inp_train, inp_val, targ_train, targ_val = train_test_split(inp_tensor, targ_tensor, test_size=0.2)\n","\n","    train_dataset = tf.data.Dataset.from_tensor_slices((inp_train, targ_train))\n","    train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(batch_size, drop_remainder=True)\n","\n","    validation_dataset = tf.data.Dataset.from_tensor_slices((inp_val, targ_val))\n","    validation_dataset = validation_dataset.shuffle(BUFFER_SIZE).batch(batch_size, drop_remainder=True)\n","\n","    return train_dataset, validation_dataset, self.input_lang_tokenizer, self.target_lang_tokenizer\n","  "],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iFAUasn7S6vh"},"source":["Now we define some important parameters "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-i9hwcF84Ea","executionInfo":{"status":"ok","timestamp":1627454870273,"user_tz":-120,"elapsed":7859,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}},"outputId":"115fa586-337d-4ec6-a85a-e3f507d64eec"},"source":["buffer_size = 32000\n","batch_size = 64\n","num_examples = 30000\n","dataset_creator = CreateDataset()\n","train_data, val_data, inp_tok, targ_tok = dataset_creator(buffer_size, github_url, num_examples, batch_size)\n","\n","example_inp_batch, example_targ_batch = next(iter(train_data))\n","vocab_inp_size = len(inp_tok.word_index) + 1\n","vocab_targ_size = len(targ_tok.word_index) + 1\n","max_len_inp = example_inp_batch.shape[1]\n","max_len_targ = example_targ_batch.shape[1]\n","embedding_dim = 256\n","units = 1024\n","\n","print(max_len_inp, max_len_targ)\n","print(vocab_inp_size)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Downloading data from https://raw.githubusercontent.com/PelFritz/Machine-Learning-courses-IPK/master/Data/deu.txt\n","37691392/37686235 [==============================] - 0s 0us/step\n","12 8\n","10452\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mFJbU5TM-_u6"},"source":["**Building the sequence to sequence Model**\n","\n","---\n","We will begin building our sequence to sequence model by first building the encoder network. This network will contain an embedding layer and a single LSTM layer.\n","\n","\n","---\n","**LSTM** stands for long short term memory. This are the building blocks of recurrent neural networks. They are an upgrade of simple recurrent neural network cells because they have some kind of memory state and can recall longer steps into the past as compared to simple rnn cells.\n","\n","**GRU** stands for gated recurrent unit. It is an alternative but simplified version of LSTM which also works quite well. \n","\n"]},{"cell_type":"code","metadata":{"id":"PlB0bl1HAKvQ","executionInfo":{"status":"ok","timestamp":1627454870274,"user_tz":-120,"elapsed":10,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}}},"source":["# ENCODER\n","\n","class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_size, enc_units, batch_size):\n","    super(Encoder, self).__init__()\n","    self.batch_size = batch_size\n","    self.enc_units = enc_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","\n","    # ---LSTM layer for encoder--- #\n","    self.lstm_layer = tf.keras.layers.LSTM(units=self.enc_units, return_state=True, return_sequences=True, recurrent_initializer='glorot_uniform')\n","  \n","  def call(self, x, hidden):\n","    x = self.embedding(x)\n","    output, h, c = self.lstm_layer(x, initial_state=hidden)\n","    return output, h, c\n","  \n","  def initialize_hidden_state(self):\n","    return [tf.zeros((self.batch_size, self.enc_units)), tf.zeros((self.batch_size, self.enc_units))]\n","\n","\n","encoder = Encoder(vocab_inp_size, embedding_dim, units, batch_size)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpgekm0pZize"},"source":["**Test what we have so far!!!!**\n","\n","---\n","\n","\n","We test the enoder Stack to see if it works well with no surprises or wrong in \n","or outputs."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQgXIjSjZ1cA","executionInfo":{"status":"ok","timestamp":1627454870796,"user_tz":-120,"elapsed":530,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}},"outputId":"e863c821-e42a-4d94-b128-b373dbc88b0c"},"source":["sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_h, sample_c = encoder(example_inp_batch, sample_hidden)\n","print('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print('Encoder h vector shape: (batch_size, units) {}'.format(sample_h.shape))\n","print('Encoder c vector shape: (batch_size, units) {}'.format(sample_c.shape))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Encoder output shape: (batch size, sequence length, units) (64, 12, 1024)\n","Encoder h vector shape: (batch_size, units) (64, 1024)\n","Encoder c vector shape: (batch_size, units) (64, 1024)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-DIqp1tqkRYP"},"source":["**Now we build the decoder model!!!**\n","\n","---\n","The decoder network is the second part of our sequence to sequence model. This is where the magic happens. The decoder does the translation magic.\n","\n","---\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"MqE0mSIMoOEe","executionInfo":{"status":"ok","timestamp":1627454870798,"user_tz":-120,"elapsed":11,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}}},"source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_size, dec_units, batch_size, attention_type='luong'):\n","    super(Decoder, self).__init__()\n","    self.batch_size = batch_size\n","    self.dec_units = dec_units\n","    self.attention_type = attention_type\n","\n","    #-----Embedding layer Decoder----#\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","\n","    # Final dense layer on which softmax will be applied\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # Fundamental cell in decoder recurrent structure\n","    self.decoder_rnn_cell = tf.keras.layers.LSTMCell(self.dec_units)\n","\n","    # Attention mechanism\n","    self.attention_mechanism = self.build_attention_mechanism(self.dec_units, None, self.batch_size*[max_len_inp], self.attention_type )\n","\n","    # sampler\n","    self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n","\n","    # Define decoder with respect to basic rnn cell, see official tensorflow site for more understnding\n","    self.rnn_cell = self.build_rnn_cell()\n","    self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\n","\n","  def build_attention_mechanism(self, dec_units, memory, memory_sequence_length, attention_type='luong'):\n","    # attention_type: type of attention to use, bahdanau or luong\n","    # dec_units: final dimension of attention layers\n","    # memory:   encoder hidden states of shape (batch size, max_length, enc_units)\n","    # memory_sequence_length: 1d array of shape (batch size) with every element set to max_length_input (for masking purpose)\n","\n","    if attention_type == 'bahdanau':\n","      return tfa.seq2seq.BahdanauAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length,)\n","    else:\n","      return tfa.seq2seq.LuongAttention(units=dec_units, memory=memory, memory_sequence_length=memory_sequence_length)\n","  \n","    \n","\n","  def build_rnn_cell(self):\n","    rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell, self.attention_mechanism, attention_layer_size=self.dec_units)\n","    return rnn_cell\n","  \n","\n","  def build_initial_state(self, batch_size, encoder_state, Dtype):\n","    decoder_initial_state = self.rnn_cell.get_initial_state(batch_size=batch_size, dtype=Dtype)\n","    decoder_initial_state =decoder_initial_state.clone(cell_state=encoder_state)\n","    return decoder_initial_state\n","\n","  def call(self, inputs, initial_state):\n","    x = self.embedding(inputs)\n","    output, _, _, = self.decoder(x, initial_state=initial_state, sequence_length=self.batch_size*[max_len_targ-1])\n","    return output \n","\n","\n","decoder = Decoder(vocab_targ_size, embedding_dim, units, batch_size, attention_type='luong')"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v3UhqfwDxRLt"},"source":["**Test what we have so far!!!**\n","\n","---\n","We test our decoder stack just as we tested our encoder stack to ensure we have no surprises or bugs.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BuVqHy5exoFy","executionInfo":{"status":"ok","timestamp":1627454873203,"user_tz":-120,"elapsed":2412,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}},"outputId":"24b12327-1c4b-44a4-d363-3bf7a2e7ff55"},"source":["sample_x = tf.random.uniform((batch_size, max_len_targ))\n","decoder.attention_mechanism.setup_memory(sample_output) # the sample output is for the memory argument\n","initial_state = decoder.build_initial_state(batch_size, [sample_h, sample_c], tf.float32)\n","\n","sample_decoder_outputs = decoder(sample_x, initial_state)\n","print('Decoder output shape: ', sample_decoder_outputs.rnn_output.shape)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Decoder output shape:  (64, 7, 6597)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vH8UpJb01qjL"},"source":["**Loss Function and Optimizer**\n","\n","---\n","Now we build a loss function and our optimizer. In this tutorial we selected Adam optimizer. You can try other optimizers from tensorflow and see if the work better.\n"]},{"cell_type":"code","metadata":{"id":"MT2_Tw4a2DCf","executionInfo":{"status":"ok","timestamp":1627454873204,"user_tz":-120,"elapsed":7,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}}},"source":["optimizer = tf.keras.optimizers.Adam()\n","\n","def loss_functiion(real, pred):\n","  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","  loss = cross_entropy(y_true=real, y_pred=pred)\n","  mask = tf.logical_not(tf.math.equal(real, 0))\n","  mask = tf.cast(mask, dtype=loss.dtype)\n","  loss = mask*loss\n","  loss = tf.reduce_mean(loss)\n","  return loss"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"fckLDX4G7Zq9","executionInfo":{"status":"ok","timestamp":1627454873204,"user_tz":-120,"elapsed":6,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}}},"source":["# Create checpoints to save model so we can call it after training to translate for us\n","checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"To0CV9KJ8J2h"},"source":["**Build training function**\n","\n","\n","---\n","1. *@tf.function* : is a constructor that helps speed computation time of our *train_step* function\n","\n","2. *GradientTape* : When we train neural networks we use backpropagation to update weights. Tensorflow needs to keep track of which operations happened during the forward pass of the network so it can back propagate the gradients. This is were GradientTape steps in. It records (\"tape\") the relevant operations operations for us.\n","3. *tape.gradient*: Once we have recorded the relevant operations, we use the GradientTape.gradient to calculate the gradient of our loss with respect to our model variables.\n","\n","\n","---\n","We do all of this detailed work because we are not using tensorflow built loops like the model.fit and model.call\n","\n"]},{"cell_type":"code","metadata":{"id":"fOnUrX6kAaOL","executionInfo":{"status":"ok","timestamp":1627454873205,"user_tz":-120,"elapsed":6,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}}},"source":["@tf.function\n","def train_step(input, target, enc_hidden):\n","  loss=0\n","\n","  with tf.GradientTape() as tape:\n","    enc_output, enc_h, enc_c = encoder(input, enc_hidden)\n","\n","    dec_input = target[:, :-1] # ignore the <end> token\n","    real = target[:, 1:] # ignore the <start> token\n","\n","    # set attention mechanism with encoder outputs\n","    decoder.attention_mechanism.setup_memory(enc_output)\n","    # create AttentionWrapperState as initial_state for decoder\n","    decoder_initial_state = decoder.build_initial_state(batch_size, [enc_h, enc_c], tf.float32)\n","    pred = decoder(dec_input, decoder_initial_state)\n","    logits = pred.rnn_output\n","    loss = loss_functiion(real, logits)\n","  \n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","  gradients = tape.gradient(loss, variables) # calculate gradient of loss w.r.t variables\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return loss"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1O89DV8_LhWt"},"source":["**Train model inside a loop for 10 epochs**\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CHjzl8xhLnLv","executionInfo":{"status":"ok","timestamp":1627466063574,"user_tz":-120,"elapsed":5893507,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}},"outputId":"42e3698f-6b44-48cf-fac4-aaa3265ab01c"},"source":["Epochs = 10\n","steps_per_epoch = num_examples//batch_size\n","\n","for epoch in range(Epochs):\n","  start = time.time()\n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(train_data.take(steps_per_epoch)):\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","    total_loss += batch_loss\n","\n","    # print the loss after every 100 batch\n","    if batch % 100 == 0:\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1,\n","                                                   batch,\n","                                                   batch_loss.numpy()))\n","    \n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix=checkpoint_prefix)\n","  \n","  print('Epoch {} Loss {:.4f}'.format(epoch+1,\n","                                      total_loss/ steps_per_epoch))\n","  print('Time taken to complete epoch {}'.format(time.time() - start))\n","  \n","      "],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 5.6732\n","Epoch 1 Batch 100 Loss 2.5265\n","Epoch 1 Batch 200 Loss 2.3700\n","Epoch 1 Batch 300 Loss 2.2364\n","Epoch 1 Loss 2.0541\n","Time taken to complete epoch 1150.8677504062653\n","Epoch 2 Batch 0 Loss 1.8535\n","Epoch 2 Batch 100 Loss 1.9676\n","Epoch 2 Batch 200 Loss 1.7979\n","Epoch 2 Batch 300 Loss 1.5734\n","Epoch 2 Loss 1.3800\n","Time taken to complete epoch 1117.8610577583313\n","Epoch 3 Batch 0 Loss 1.1543\n","Epoch 3 Batch 100 Loss 1.2249\n","Epoch 3 Batch 200 Loss 1.1717\n","Epoch 3 Batch 300 Loss 1.1390\n","Epoch 3 Loss 0.9647\n","Time taken to complete epoch 1129.5855646133423\n","Epoch 4 Batch 0 Loss 0.8140\n","Epoch 4 Batch 100 Loss 0.8012\n","Epoch 4 Batch 200 Loss 0.8388\n","Epoch 4 Batch 300 Loss 0.7309\n","Epoch 4 Loss 0.6569\n","Time taken to complete epoch 1094.1770067214966\n","Epoch 5 Batch 0 Loss 0.5274\n","Epoch 5 Batch 100 Loss 0.5309\n","Epoch 5 Batch 200 Loss 0.5817\n","Epoch 5 Batch 300 Loss 0.5606\n","Epoch 5 Loss 0.4522\n","Time taken to complete epoch 1104.8975496292114\n","Epoch 6 Batch 0 Loss 0.4332\n","Epoch 6 Batch 100 Loss 0.3591\n","Epoch 6 Batch 200 Loss 0.4464\n","Epoch 6 Batch 300 Loss 0.5117\n","Epoch 6 Loss 0.3230\n","Time taken to complete epoch 1103.6252834796906\n","Epoch 7 Batch 0 Loss 0.2593\n","Epoch 7 Batch 100 Loss 0.2772\n","Epoch 7 Batch 200 Loss 0.2866\n","Epoch 7 Batch 300 Loss 0.3505\n","Epoch 7 Loss 0.2437\n","Time taken to complete epoch 1161.9464514255524\n","Epoch 8 Batch 0 Loss 0.2144\n","Epoch 8 Batch 100 Loss 0.3729\n","Epoch 8 Batch 200 Loss 0.2572\n","Epoch 8 Batch 300 Loss 0.2843\n","Epoch 8 Loss 0.1943\n","Time taken to complete epoch 1116.7318234443665\n","Epoch 9 Batch 0 Loss 0.1026\n","Epoch 9 Batch 100 Loss 0.1740\n","Epoch 9 Batch 200 Loss 0.1966\n","Epoch 9 Batch 300 Loss 0.2240\n","Epoch 9 Loss 0.1618\n","Time taken to complete epoch 1105.4871327877045\n","Epoch 10 Batch 0 Loss 0.1337\n","Epoch 10 Batch 100 Loss 0.1383\n","Epoch 10 Batch 200 Loss 0.1221\n","Epoch 10 Batch 300 Loss 0.1860\n","Epoch 10 Loss 0.1447\n","Time taken to complete epoch 1105.176881313324\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nObrSuWuO2eM"},"source":["**Now we evaluate our sentence**\n","---\n","Here we build an inference function that takes in an input sentence and sends out the predictions.\n","1. We used the *TrainingSampler* for training but for inference we will use the *GreedyEmbeddingsampler*.\n"]},{"cell_type":"code","metadata":{"id":"T6kDOoddO5qk","executionInfo":{"status":"ok","timestamp":1627466063575,"user_tz":-120,"elapsed":4,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}}},"source":["def evaluate_sentence(sentence):\n","  sentence = dataset_creator.preprocess(sentence)\n","\n","  inputs = [inp_tok.word_index[i] for i in sentence.split(' ')]\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences(sequences=[inputs], maxlen=max_len_inp, padding='post')\n","  inputs= tf.convert_to_tensor(inputs)\n","  inference_batch_size = inputs.shape[0]\n","\n","  enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size, units))]\n","  enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n","\n","  start_tokens = tf.fill([inference_batch_size], targ_tok.word_index['<start>'])\n","  end_token = targ_tok.word_index['<end>']\n","\n","  greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n","  decoder_instance = tfa.seq2seq.BasicDecoder(cell=decoder.rnn_cell, sampler=greedy_sampler, output_layer=decoder.fc)\n","  # setup memory in decoder stack\n","  decoder.attention_mechanism.setup_memory(enc_out)\n","\n","  # set decoder initial state\n","  decoder_initial_state = decoder.build_initial_state(inference_batch_size, [enc_h, enc_c], tf.float32)\n","\n","  # Since the BasicDecoder wraps around the decoders rnn sell only, you have to ensure that the inputs to the Basic\n","  # decoder decoding step is output of the embedding layer. GreedySEmbeddingSampling takes care of this. \n","  # We only get the weights of the embedding layer and pass them to the Basicdecoder\n","\n","  decoder_embedding_matrix = decoder.embedding.variables[0]\n","  output, _, _ = decoder_instance(decoder_embedding_matrix, start_tokens=start_tokens, end_token=end_token,\n","                         initial_state=decoder_initial_state)\n","  \n","  return output.sample_id.numpy()\n"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u_3d0C7-O6Dd"},"source":["**Hurray you can now translate!!!**\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"bAtv4D-7Zcng","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627466488746,"user_tz":-120,"elapsed":1254,"user":{"displayName":"Fritz Forbang","photoUrl":"","userId":"12957595507620375437"}},"outputId":"694cceac-d614-4768-b36c-e96cdb785a92"},"source":["def translator(sentence):\n","  result = evaluate_sentence(sentence)\n","  print(result)\n","  result = targ_tok.sequences_to_texts(result)\n","  print('Input: %s'%(sentence))\n","  print('Translation: {}'.format(result))\n","\n","# Restore last checkpoint and translate\n","checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n","translator(u'wann kommst du?')\n","translator(u'wo bist du?')\n","translator(u'wo sind Sie')\n","translator(u'Ich habe Hunger')  # I love food, so one food's sake\n","translator(u'Du bist klug')\n","\n","print('\\n Some translations are wrong \\n')\n","translator(u'Er ist der Mann')"],"execution_count":34,"outputs":[{"output_type":"stream","text":["[[274  23   6 838   3]]\n","Input: wann kommst du?\n","Translation: ['when are you coming? <end>']\n","[[68 23 74  3]]\n","Input: wo bist du?\n","Translation: ['where are you? <end>']\n","[[68 23 74  3]]\n","Input: wo sind Sie\n","Translation: ['where are you? <end>']\n","[[  4  13 240   3]]\n","Input: Ich habe Hunger\n","Translation: ['i m hungry. <end>']\n","[[  6  16 571   3]]\n","Input: Du bist klug\n","Translation: ['you re smart. <end>']\n","\n"," Some translations are wrong \n","\n","[[ 21   8 106 669   3]]\n","Input: Er ist der Mann\n","Translation: ['that s his seat. <end>']\n"],"name":"stdout"}]}]}